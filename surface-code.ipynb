{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fb789e",
   "metadata": {},
   "source": [
    "# Surface Code\n",
    "\n",
    "Ref: https://www.nature.com/articles/s41586-022-05434-1 - d=3 Implementation\n",
    "https://www.nature.com/articles/s41586-022-04566-8 - More on implementation\n",
    "https://arxiv.org/html/2307.14989v4/#S5.F7 - Diagrams\n",
    "\n",
    "\n",
    "Core on roateted: https://arxiv.org/pdf/2409.14765\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8af2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical Error without correction: 0.48\n",
      "Logical Error with correction: 0.54\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import qsharp\n",
    "from itertools import combinations\n",
    "import pymatching\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def convert_syndrome(syndrome_results):\n",
    "    return np.array([1 if bit == qsharp.Result.One else 0 for bit in syndrome_results], dtype=np.uint8)\n",
    "\n",
    "\n",
    "def getZCorrections(d, initMeasures, xMaps):\n",
    "    num_qubits = d*d\n",
    "    H_x = np.zeros((len(initMeasures), num_qubits), dtype=np.uint8)\n",
    "    for i, stabilizer in enumerate(xMaps):\n",
    "        for qubit_idx in stabilizer:\n",
    "            H_x[i, qubit_idx] = 1\n",
    "\n",
    "\n",
    "    z_decoder = pymatching.Matching(H_x) \n",
    "    z_correction = z_decoder.decode(initMeasures)\n",
    "    # print(z_correction)\n",
    "    z_error_qubits = np.where(z_correction == 1)[0]  # Qubits needing phase flips\n",
    "    print(\"Apply phase flips (Z) to qubits:\", z_error_qubits)\n",
    "    return z_error_qubits\n",
    "\n",
    "\n",
    "def flatten_syndrome_timeline(syndrome_matrix):\n",
    "    if syndrome_matrix.shape[0] == 1:\n",
    "        return syndrome_matrix[0]\n",
    "    return syndrome_matrix.flatten()\n",
    "\n",
    "def getSyndrome(a,b,c,d):\n",
    "    return [i!=j for i,j in zip(a,b)], [i!=j for i,j in zip(c,d)]\n",
    "\n",
    "\n",
    "class PauliTracker:\n",
    "    '''Tracks the Pauli X&Z stabilizers measurements, Record \n",
    "    the stabilizer measurement outcomes in each round without\n",
    "    physically correcting the qubits'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.XKEY = \"X\"\n",
    "        self.ZKEY = \"Z\"\n",
    "        self.tracker = {self.XKEY: [], self.ZKEY: []}\n",
    "\n",
    "    def track(self, xMeasures, zMeasures):\n",
    "        self.tracker[self.XKEY].append(xMeasures)\n",
    "        self.tracker[self.ZKEY].append(zMeasures)\n",
    "    \n",
    "    def getX(self):\n",
    "        return self.tracker[self.XKEY]\n",
    "    def getZ(self):\n",
    "        return self.tracker[self.ZKEY]\n",
    "\n",
    "\n",
    "def addTimeStep():\n",
    "    xMaps, initXMeasures, zMaps, initZMeasures = qsharp.eval(f\"RotatedSurfaceCode.GenerateLattice(d, qubits);\")\n",
    "    PAULI_TRACKER.track(initXMeasures, initZMeasures)\n",
    "    return xMaps, initXMeasures, zMaps, initZMeasures\n",
    "\n",
    "def convert_syndrome(syndrome_results):\n",
    "    return np.array([1 if bit == qsharp.Result.One else 0 for bit in syndrome_results], dtype=np.uint8)\n",
    "\n",
    "def getCorrections(d, p, syndrome, maps):\n",
    "    num_qubits = d*d\n",
    "    H = np.zeros((len(maps), num_qubits), dtype=np.uint8)\n",
    "    \n",
    "    for i, stabilizer in enumerate(maps):\n",
    "        for qubit_idx in stabilizer:\n",
    "            H[i, qubit_idx] = 1\n",
    "\n",
    "    weights = np.ones(H.shape[1]) * np.log((1 - p) / p)\n",
    "    decoder = pymatching.Matching(H, weights=weights) \n",
    "    correction = decoder.decode(syndrome)\n",
    "    error_qubits = np.where(correction == 1)[0]  # Qubits needing flips\n",
    "    # print(error_qubits)\n",
    "    # print(\"Apply flips to qubits:\", error_qubits)\n",
    "    return error_qubits\n",
    "\n",
    "from collections import defaultdict\n",
    "def decode_surface_code(parity_checks, stabilizer_qubit_map):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        parity_checks (List[int]): List of 0 or 1 values for each stabilizer (1 = error detected)\n",
    "        stabilizer_qubit_map (List[List[int]]): List of lists, each with qubit indices for the stabilizer\n",
    "\n",
    "    Returns:\n",
    "        Set[int]: Indices of qubits to apply correction to\n",
    "    \"\"\"\n",
    "\n",
    "    # Count how many times each qubit appears in stabilizers with parity 1\n",
    "    qubit_votes = defaultdict(int)\n",
    "\n",
    "    for stab_index, parity in enumerate(parity_checks):\n",
    "        if parity == 1:\n",
    "            for q in stabilizer_qubit_map[stab_index]:\n",
    "                qubit_votes[q] += 1\n",
    "\n",
    "    # Apply correction to qubits that are involved in an odd number of violated stabilizers\n",
    "    corrections = {q for q, count in qubit_votes.items() if count % 2 == 1}\n",
    "    return corrections\n",
    "\n",
    "def applyCorrection(correct, zp, xp, zMeasures, zMaps, xMeasures, xMaps):\n",
    "    if correct:\n",
    "        x_correction = getCorrections(d, xp,  convert_syndrome(zMeasures), zMaps)\n",
    "        z_correction = getCorrections(d, zp, convert_syndrome(xMeasures), xMaps)\n",
    "        print(x_correction)\n",
    "        for q in x_correction:\n",
    "            qsharp.eval(f\"X(qubits[{q}]);\")\n",
    "        for q in z_correction:\n",
    "            qsharp.eval(f\"Z(qubits[{q}]);\")\n",
    "\n",
    "\n",
    "def runLogicalQubit(d, layers, xnoise, znoise, correct=False):\n",
    "    TOTAL_DATA_QUBITS = d*d\n",
    "    PAULI_TRACKER = PauliTracker()\n",
    "    qsharp.init(project_root=\".\")\n",
    "    qsharp.eval(f\"import Std.Diagnostics.ConfigurePauliNoise;\")\n",
    "    qsharp.eval(f\"import Std.Arrays.ForEach;\")\n",
    "    qsharp.eval(f\"let d = {d};\")\n",
    "    qsharp.eval(f\"let TOTAL_DATA_QUBITS = {TOTAL_DATA_QUBITS};\")\n",
    "    qsharp.eval(\"use qubits = Qubit[TOTAL_DATA_QUBITS];\")\n",
    "    qsharp.eval(\"ApplyToEach(X, qubits);\")\n",
    "    qsharp.eval(f\"ConfigurePauliNoise({xnoise}, 0.0, {znoise});\")\n",
    "    qsharp.eval(\"ResetAll(qubits);\")\n",
    "\n",
    "    xMaps, initXMeasures, zMaps, initZMeasures = addTimeStep()\n",
    "\n",
    "\n",
    "    # x_correction = getCorrections(d, initZMeasures, zMaps)\n",
    "    # z_correction = getCorrections(d, initXMeasures, xMaps)\n",
    "    # # for q in x_correction:\n",
    "    # #     qsharp.eval(f\"X(qubits[{q}]);\")\n",
    "    # # for q in z_correction:\n",
    "    # #     qsharp.eval(f\"Z(qubits[{q}]);\")\n",
    "    # applyCorrection(correct, znoise, xnoise, initZMeasures, zMaps, initXMeasures, xMaps)\n",
    "    corrupt = False\n",
    "    for i in range(layers):\n",
    "        x , xMeasures, z, zMeasures = addTimeStep()\n",
    "        # applyCorrection(correct, znoise, xnoise, zMeasures, zMaps, xMeasures, xMaps)\n",
    "        xSyndrome, zSyndrome = getSyndrome(initXMeasures, xMeasures, initZMeasures, zMeasures)\n",
    "        # if any(zSyndrome):\n",
    "        #     corrupt = True\n",
    "        \n",
    "            # x , xMeasures, z, zMeasures = addTimeStep()\n",
    "        \n",
    "        # print(f\"Visualize If any errors for time({i})\")\n",
    "        # print(\"X\", xSyndrome)\n",
    "        # print(\"Z\", zSyndrome)\n",
    "        \n",
    "        initXMeasures = xMeasures\n",
    "        initZMeasures = zMeasures\n",
    "    # xSyndrome, zSyndrome = getSyndrome(initXMeasures, xMeasures, initZMeasures, zMeasures)\n",
    "    \n",
    "    # results = qsharp.eval(\"ForEach(x => Measure([PauliZ], [x]), qubits);\")\n",
    "    results = []\n",
    "    re = []\n",
    "    s = d-1\n",
    "    for i in range(0, d*d):\n",
    "        # if ((i//d)*(d+1)) == i:\n",
    "            # re.append(i)\n",
    "            # s-=1\n",
    "            results.append(qsharp.eval(f\"Measure([PauliZ], [qubits[{i}]]);\"))\n",
    "    # print(re)\n",
    "    # print(results)\n",
    "    # for i in range(0, TOTAL_DATA_QUBITS, d):\n",
    "    #     print(results[i:i+d])\n",
    "    # print(sum(convert_syndrome(results))%2)\n",
    "    # print(f\"Final Logical State: {sum(convert_syndrome(results))%2}\")\n",
    "    return int(not sum(convert_syndrome(results))%2)\n",
    "    \n",
    "\n",
    "qsharp.eval(\"ResetAll(qubits);\")\n",
    "\n",
    "d = 3\n",
    "layers = 4\n",
    "xnoise = 0.01\n",
    "znoise = 0.0\n",
    "SHOTS = 100\n",
    "def failure(r):\n",
    "    return 1 - (sum(r)/SHOTS)\n",
    "\n",
    "r = []\n",
    "for i in range(SHOTS):\n",
    "    r.append(runLogicalQubit(d, layers, xnoise, znoise, correct=False))\n",
    "print(f\"Logical Error without correction: {failure(r)}\")\n",
    "\n",
    "r = []\n",
    "for i in range(SHOTS):\n",
    "    r.append(runLogicalQubit(d, layers, xnoise, znoise, correct=True))\n",
    "print(f\"Logical Error with correction: {failure(r)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d451f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for code distance d=1\n",
      "Physical error rate p=0.005\n",
      "Physical error rate p=0.010\n",
      "Physical error rate p=0.050\n",
      "Physical error rate p=0.100\n",
      "Physical error rate p=0.150\n",
      "Physical error rate p=0.200\n",
      "Running for code distance d=3\n",
      "Physical error rate p=0.005\n",
      "Physical error rate p=0.010\n",
      "Physical error rate p=0.050\n",
      "Physical error rate p=0.100\n",
      "Physical error rate p=0.150\n",
      "Physical error rate p=0.200\n",
      "Running for code distance d=5\n",
      "Physical error rate p=0.005\n",
      "Physical error rate p=0.010\n",
      "Physical error rate p=0.050\n",
      "Physical error rate p=0.100\n",
      "Physical error rate p=0.150\n",
      "Physical error rate p=0.200\n",
      "{1: [0.008, 0.014, 0.096, 0.179, 0.267, 0.299], 3: [0.073, 0.149, 0.422, 0.468, 0.474, 0.511], 5: [0.133, 0.22, 0.48, 0.505, 0.513, 0.493]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymatching\n",
    "import matplotlib.pyplot as plt\n",
    "import qsharp\n",
    "import pymatching\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def convert_syndrome(syndrome_results):\n",
    "    return np.array([1 if bit == qsharp.Result.One else 0 for bit in syndrome_results], dtype=np.uint8)\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, d,p, maps):\n",
    "        self.d = d\n",
    "        self.num_qubits = d*d\n",
    "        \n",
    "        self.H = np.zeros((len(maps), self.num_qubits), dtype=np.uint8)\n",
    "        for i, stabilizer in enumerate(maps):\n",
    "            for qubit_idx in stabilizer:\n",
    "                self.H[i, qubit_idx] = 1\n",
    "        \n",
    "        weights = np.ones(self.H.shape[1]) * np.log((1 - p) / p)\n",
    "        self.decoder = pymatching.Matching(self.H, weights=weights) \n",
    "\n",
    "    def decode(self, syndrome):\n",
    "        return self.decoder.decode(syndrome)\n",
    "    \n",
    "    def decode_batch(self, syndromes):\n",
    "        return self.decoder.decode_batch(syndromes)\n",
    "\n",
    "    def getErrorQubits(self, correction):\n",
    "        return np.where(correction == 1)[0]\n",
    "\n",
    "def qsharp_runner(d,p, shots):\n",
    "    qsharp.init(project_root=\".\")\n",
    "    # qsharp.eval(f\"import Std.Diagnostics.ConfigurePauliNoise;\")\n",
    "    # qsharp.eval(f\"import Std.Arrays.ForEach;\")\n",
    "    # qsharp.eval(f\"let d = {d};\")\n",
    "    # qsharp.eval(f\"let TOTAL_DATA_QUBITS = {TOTAL_DATA_QUBITS};\")\n",
    "    # qsharp.eval(\"use qubits = Qubit[TOTAL_DATA_QUBITS];\")\n",
    "    # # qsharp.eval(\"ApplyToEach(X, qubits);\")\n",
    "    # qsharp.eval(f\"ConfigurePauliNoise({p}, 0.0, 0.0);\")\n",
    "    # qsharp.eval(\"ResetAll(qubits);\")\n",
    "    xMaps, zMaps = qsharp.eval(f\"RotatedSurfaceCode.GetMaps({d});\")\n",
    "    \n",
    "\n",
    "    results = qsharp.run(f\"RotatedSurfaceCode.RotatedSurfaceCode({d}, {d})\", shots=shots, noise=qsharp.BitFlipNoise(p))\n",
    "    zSyndromes = []\n",
    "    trueValues = []\n",
    "    for result in results:\n",
    "        zSyndromes.append(convert_syndrome(result[len(xMaps):len(xMaps)+len(zMaps)]))\n",
    "        trueValues.append(convert_syndrome(result[len(xMaps)+len(zMaps):]))\n",
    "\n",
    "    # results = qsharp.eval(\"ForEach(x => Measure([PauliZ], [x]), qubits);\")\n",
    "    # results = []\n",
    "    # for i in range(0, d*d):\n",
    "    #     # if (i%(d+1))== 0:\n",
    "    #         results.append(1 if qsharp.eval(f\"Measure([PauliZ], [qubits[{i}]]);\") == qsharp.Result.One else 0)\n",
    "    # trueLogicalValue = int((sum(convert_syndrome(results))%2))\n",
    "    return zSyndromes, zMaps, trueValues\n",
    "\n",
    "\n",
    "def is_logical_error(d, correction, true_logical):\n",
    "    def getParity(d, correction):\n",
    "        r = []\n",
    "        correctionParity = 0\n",
    "        for i in range(d):\n",
    "            # r.append((i+1)*(d-1))\n",
    "            # if correction[(d*d)-(i+1)]:\n",
    "            if correction[(i+1)*(d-1)]:\n",
    "                correctionParity = 0 if correctionParity else 1\n",
    "        # print(r)\n",
    "        return correctionParity\n",
    "    \n",
    "    return (int(getParity(d, true_logical))) != (int(getParity(d, true_logical)))\n",
    "    \n",
    "    \n",
    "\n",
    "def run_experiment_for_d(d_values, p_values, num_trials):\n",
    "    results = {}\n",
    "    for d in d_values:\n",
    "        logical_error_rates = []\n",
    "        print(f\"Running for code distance d={d}\")\n",
    "\n",
    "        for p in p_values:\n",
    "            logical_errors = 0\n",
    "            print(f\"Physical error rate p={p:.3f}\")\n",
    "            syndrome, maps, true_logical = qsharp_runner(d, p, num_trials)\n",
    "            \n",
    "            decoder = Decoder(d,p, maps)\n",
    "            correction = decoder.decode_batch(syndrome)\n",
    "\n",
    "            # Check if correction flips the logical qubit\n",
    "            logical_errors = sum(is_logical_error(d, c, true_logical[i]) for i,c in enumerate(correction))\n",
    "            logical_error_rates.append(logical_errors / num_trials)\n",
    "\n",
    "        results[d] = logical_error_rates\n",
    "\n",
    "    return results\n",
    "\n",
    "print(run_experiment_for_d(d_values=[1, 3, 5], p_values=[0.005, 0.01, 0.05, 0.1, 0.15, 0.2], num_trials=1000))\n",
    "# print(run_experiment_for_d(d_values=[1, 3, 5], p_values=[0.005, 0.01, 0.05, 0.1, 0.15, 0.2], num_trials=11000))\n",
    "#{1: [0.010181818181818183, 0.01818181818181818, 0.098, 0.1809090909090909, 0.2540909090909091, 0.31836363636363635], 3: [0.07636363636363637, 0.14945454545454545, 0.43618181818181817, 0.48918181818181816, 0.5086363636363637, 0.4979090909090909], 5: [0.15163636363636362, 0.2737272727272727, 0.49772727272727274, 0.5010909090909091, 0.49536363636363634, 0.5014545454545455]}\n",
    "\n",
    "# print(run_experiment_for_d(d_values=[3], p_values=[0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7], num_trials=2000))\n",
    "# print(run_experiment_for_d(d_values=[3], p_values=[0.005], num_trials=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08a20a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal) is available!\n",
      "mps\n",
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision torchaudio\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS (Metal) is available!\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS not available, using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "lattice = torch.zeros((5, 5), dtype=torch.uint8, device=device)\n",
    "syndrome = torch.ones((5, 5), dtype=torch.uint8, device=device)\n",
    "\n",
    "lattice ^= syndrome\n",
    "print(lattice.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd58514",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyobjc\n",
    "import numpy as np\n",
    "import objc\n",
    "from Cocoa import NSObject\n",
    "import Metal\n",
    "import MetalKit\n",
    "\n",
    "# 1. Create Metal device\n",
    "device = Metal.MTLCreateSystemDefaultDevice()\n",
    "\n",
    "# 2. Load shader\n",
    "source = open(\"my_shader.metal\").read()\n",
    "options = {}\n",
    "compile_error = None\n",
    "library = device.newLibraryWithSource_options_error_(source, options, objc.nil)\n",
    "function = library.newFunctionWithName_(\"add_one\")\n",
    "\n",
    "# 3. Create compute pipeline\n",
    "pipeline_state, err = device.newComputePipelineStateWithFunction_error_(function, None)\n",
    "\n",
    "# 4. Input/output buffers\n",
    "array = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "buffer_size = array.nbytes\n",
    "\n",
    "input_buffer = device.newBufferWithBytes_length_options_(array.tobytes(), buffer_size, 0)\n",
    "output_buffer = device.newBufferWithLength_options_(buffer_size, 0)\n",
    "\n",
    "# 5. Create command queue and encoder\n",
    "command_queue = device.newCommandQueue()\n",
    "command_buffer = command_queue.commandBuffer()\n",
    "command_encoder = command_buffer.computeCommandEncoder()\n",
    "\n",
    "command_encoder.setComputePipelineState_(pipeline_state)\n",
    "command_encoder.setBuffer_offset_atIndex_(input_buffer, 0, 0)\n",
    "command_encoder.setBuffer_offset_atIndex_(output_buffer, 0, 1)\n",
    "\n",
    "# 6. Dispatch threads\n",
    "thread_count = len(array)\n",
    "thread_group_size = pipeline_state.maxTotalThreadsPerThreadgroup()\n",
    "thread_groups = ((thread_count + thread_group_size - 1) // thread_group_size)\n",
    "command_encoder.dispatchThreadgroups_threadsPerThreadgroup_(\n",
    "    (thread_groups, 1, 1),\n",
    "    (thread_group_size, 1, 1)\n",
    ")\n",
    "\n",
    "command_encoder.endEncoding()\n",
    "command_buffer.commit()\n",
    "command_buffer.waitUntilCompleted()\n",
    "\n",
    "# 7. Get results\n",
    "result_ptr = output_buffer.contents()\n",
    "result = np.frombuffer(objc.pythonify(result_ptr), dtype=np.float32, count=len(array))\n",
    "print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def generate_all_single_pauli_errors(num_qubits: int) -> List[np.ndarray]:\n",
    "    \"\"\"Generates all single X/Z/Y errors on a code block.\"\"\"\n",
    "    errors = []\n",
    "    for q in range(num_qubits):\n",
    "        e = np.zeros(num_qubits, dtype=int)\n",
    "        e[q] = 1\n",
    "        errors.append((q, e))  # single-qubit X (or Z)\n",
    "    return errors\n",
    "\n",
    "def compute_syndrome(error: np.ndarray, stab_map: List[List[int]]) -> np.ndarray:\n",
    "    \"\"\"Compute syndrome based on parity check (mod 2) for each stabilizer.\"\"\"\n",
    "    syndrome = np.zeros(len(stab_map), dtype=int)\n",
    "    for i, qubits in enumerate(stab_map):\n",
    "        parity = sum(error[q] for q in qubits if q < len(error))\n",
    "        syndrome[i] = parity % 2\n",
    "    return syndrome\n",
    "\n",
    "def build_lookup_table(num_qubits: int, stab_map: List[List[int]]) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Precompute the syndrome → correction table for all single-qubit errors.\"\"\"\n",
    "    table = {}\n",
    "\n",
    "    for q, error in generate_all_single_pauli_errors(num_qubits):\n",
    "        syndrome = compute_syndrome(error, stab_map)\n",
    "        key = ''.join(map(str, syndrome))\n",
    "        # Store only if not already stored — minimal weight correction\n",
    "        if key not in table:\n",
    "            table[key] = error.copy()\n",
    "    \n",
    "    # Add trivial correction for zero syndrome\n",
    "    table['0' * len(stab_map)] = np.zeros(num_qubits, dtype=int)\n",
    "    return table\n",
    "\n",
    "def lookup_decode(syndrome: np.ndarray, lookup_table: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "    key = ''.join(map(str, syndrome))\n",
    "    return lookup_table.get(key, np.zeros_like(next(iter(lookup_table.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aef0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurfaceCodeDecoder:\n",
    "    def __init__(self, d):\n",
    "        self.d = d  # code distance\n",
    "\n",
    "    def _get_syndrome_graph(self, syndrome):\n",
    "        # Create a graph of syndrome nodes\n",
    "        G = nx.Graph()\n",
    "        for i, node1 in enumerate(syndrome):\n",
    "            for j, node2 in enumerate(syndrome):\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                weight = self._manhattan_distance(node1, node2)\n",
    "                G.add_edge(node1, node2, weight=weight)\n",
    "        return G\n",
    "\n",
    "    def _manhattan_distance(self, a, b):\n",
    "        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "    def decode(self, syndrome):\n",
    "        G = self._get_syndrome_graph(syndrome)\n",
    "        matching = nx.algorithms.matching.min_weight_matching(G)\n",
    "        \n",
    "        # In real code, we would now apply the correction along the shortest paths\n",
    "        corrections = []\n",
    "        for u, v in matching:\n",
    "            corrections.append((u, v))  # paths to be corrected\n",
    "        return corrections\n",
    "    def getSyndrome(self, map, measures):\n",
    "        syndrome = []\n",
    "        syndromeMap = []\n",
    "        for i,measure in enumerate(measures):\n",
    "            if measure == qsharp.Result.One:\n",
    "                qubits = []\n",
    "                for qubit in map[i]:\n",
    "                    qubits.append((qubit//self.d, qubit%self.d))\n",
    "                syndrome.append((sum(q[0] for q in qubits)/len(qubits),sum(q[1] for q in qubits)/len(qubits) ))\n",
    "                syndromeMap.append(i)\n",
    "        print(syndromeMap)\n",
    "        print(syndrome)\n",
    "        return syndrome, syndromeMap\n",
    "    \n",
    "    def getCoordQubits(self, coord):\n",
    "        return (coord[0]*self.d)+coord[1]\n",
    "    \n",
    "    \n",
    "\n",
    "    def find_shortest_path(self, start, end):\n",
    "        # Round coordinates to integers\n",
    "        start_int = (round(start[0]), round(start[1]))\n",
    "        end_int = (round(end[0]), round(end[1]))\n",
    "        \n",
    "        # Calculate horizontal and vertical distances\n",
    "        x_diff = abs(end_int[0] - start_int[0])\n",
    "        y_diff = abs(end_int[1] - start_int[1])\n",
    "        \n",
    "        # Initialize the path with the starting point\n",
    "        path = [start_int]\n",
    "        \n",
    "        # Current position\n",
    "        current = start_int\n",
    "        \n",
    "        # Determine direction of movement\n",
    "        x_sign = 1 if end_int[0] > start_int[0] else -1 if end_int[0] < start_int[0] else 0\n",
    "        y_sign = 1 if end_int[1] > start_int[1] else -1 if end_int[1] < start_int[1] else 0\n",
    "        \n",
    "        # Move diagonally as much as possible\n",
    "        diagonal_steps = min(x_diff, y_diff)\n",
    "        for _ in range(diagonal_steps):\n",
    "            current = (current[0] + x_sign, current[1] + y_sign)\n",
    "            path.append(current)\n",
    "        \n",
    "        # Move remaining horizontal steps\n",
    "        remaining_x = x_diff - diagonal_steps\n",
    "        for _ in range(remaining_x):\n",
    "            current = (current[0] + x_sign, current[1])\n",
    "            path.append(current)\n",
    "        \n",
    "        # Move remaining vertical steps\n",
    "        remaining_y = y_diff - diagonal_steps\n",
    "        for _ in range(remaining_y):\n",
    "            current = (current[0], current[1] + y_sign)\n",
    "            path.append(current)\n",
    "        \n",
    "        # Return the path (excluding the starting point if it's already included)\n",
    "        return path[1:] if end_int != start_int else []\n",
    "\n",
    "\n",
    "def correctErrors(errors):\n",
    "    for error, emap in errors.items():\n",
    "      for key, apply in emap.items():\n",
    "        #   print(key, apply)\n",
    "          if apply:\n",
    "            # print(\"Applying\")\n",
    "            if error == \"x\":\n",
    "                qsharp.eval(f\"X(qubits[{key}]);\")\n",
    "            else:\n",
    "                qsharp.eval(f\"Z(qubits[{key}]);\")\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def decode_surface_code(parity_checks, stabilizer_qubit_map):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        parity_checks (List[int]): List of 0 or 1 values for each stabilizer (1 = error detected)\n",
    "        stabilizer_qubit_map (List[List[int]]): List of lists, each with qubit indices for the stabilizer\n",
    "\n",
    "    Returns:\n",
    "        Set[int]: Indices of qubits to apply correction to\n",
    "    \"\"\"\n",
    "\n",
    "    # Count how many times each qubit appears in stabilizers with parity 1\n",
    "    qubit_votes = defaultdict(int)\n",
    "\n",
    "    for stab_index, parity in enumerate(parity_checks):\n",
    "        if parity == 1:\n",
    "            for q in stabilizer_qubit_map[stab_index]:\n",
    "                qubit_votes[q] += 1\n",
    "\n",
    "    # Apply correction to qubits that are involved in an odd number of violated stabilizers\n",
    "    corrections = {q for q, count in qubit_votes.items() if count % 2 == 1}\n",
    "    return corrections\n",
    "\n",
    "\n",
    "def correct_surface_code(xcorrections, zcorrections):\n",
    "    for i in xcorrections:\n",
    "        qsharp.eval(f\"X(qubits[{i}]);\")\n",
    "    for i in zcorrections:\n",
    "        qsharp.eval(f\"Z(qubits[{i}]);\")\n",
    "\n",
    "\n",
    "def getZCorrections(d, initMeasures, xMaps):\n",
    "    num_qubits = d*d\n",
    "    H_x = np.zeros((len(initMeasures), num_qubits), dtype=np.uint8)\n",
    "    for i, stabilizer in enumerate(xMaps):\n",
    "        for qubit_idx in stabilizer:\n",
    "            H_x[i, qubit_idx] = 1\n",
    "\n",
    "\n",
    "    z_decoder = pymatching.Matching(H_x) \n",
    "    z_correction = z_decoder.decode(initMeasures)\n",
    "    print(z_correction)\n",
    "    z_error_qubits = np.where(z_correction == 1)[0]  # Qubits needing phase flips\n",
    "    print(\"Apply phase flips (Z) to qubits:\", z_error_qubits)\n",
    "    return z_error_qubits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0b9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
